{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "model = \"llama3.2\"\n",
    "doc_path = \"../samples/test_hardest.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=doc_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading (PDF example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Document Loading + extract text (image also): <a href=\"https://python.langchain.com/docs/how_to/document_loader_pdf/\">More detail to extract in future</a>\n",
    "- Document type: <a href=\"https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html\">Document</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\"\"\"\n",
    "Here, the RecursiveCharacterTextSplitter class is imported and an instance is created with specific parameters:\n",
    "\n",
    "chunk_size=512: Each chunk will have a maximum of 512 characters.\n",
    "chunk_overlap=64: Chunks will overlap by 64 characters to ensure context is preserved between chunks.\n",
    "add_start_index=True: This might be used to keep track of the starting index of each chunk in the original text.\n",
    "\"\"\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# Remember this will return a list of Document type (which main component for extract data)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explaining9typesofAPItesting 7Howisdatasentovertheinternet?WhatdoesthathavetodowiththeOSImodel?HowdoesTCP/IPfitintothis? 10Top5commonwaystoimproveAPIperformance 11Thereareover1,000engineeringblogs.Herearemytop9favorites: 15RESTAPIAuthenticationMethods 16LinuxBootProcessIllustrated 18Netflix'sTechStack 22WhatdoesACIDmean? 26Oauth2.0ExplainedWithSimpleTerms 28TheEvolvingLandscapeofAPIProtocolsin2023 30LinuxbootProcessExplained 32Explaining8PopularNetworkProtocolsin1Diagram. 34DataPipelinesOverview\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 133.44402623176575 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "vector_stores = []\n",
    "start_time = time.time()\n",
    "\n",
    "for split in all_splits:\n",
    "    vector_stores.append(embeddings.embed_query(split.page_content))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_stores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4792"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte size: 4792 bytes\n",
      "Size in megabytes: 0.00457000732421875 MB\n"
     ]
    }
   ],
   "source": [
    "# Add this new cell to convert bytes to megabytes\n",
    "byte_size = 4792\n",
    "mb_size = byte_size / 1048576\n",
    "print(f\"Byte size: {byte_size} bytes\")\n",
    "print(f\"Size in megabytes: {mb_size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.HttpClient(host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection = client.get_or_create_collection(\"test_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Collection' object has no attribute 'add_vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_vectors\u001b[49m(vector_stores)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Collection' object has no attribute 'add_vectors'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
